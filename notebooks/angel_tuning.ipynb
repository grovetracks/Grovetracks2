{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Angel Composition Prompt Tuning\n",
    "\n",
    "Interactive notebook for tuning Ollama prompts for angel drawings.\n",
    "\n",
    "**Workflow:** Edit prompts/params → re-run generation cell → see results inline in seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup — imports and connectivity checks\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helpers import (\n",
    "    Composition, AiComposition, ai_to_composition, compositions_to_few_shot,\n",
    "    call_ollama, COMPOSITION_SCHEMA, OLLAMA_SYSTEM_PROMPT, FOCUSED_SYSTEM_PROMPT,\n",
    "    get_curated, get_curated_words, save_compositions, get_connection,\n",
    "    validate, bounding_box, count_strokes, count_points,\n",
    "    draw, draw_grid, draw_comparison,\n",
    ")\n",
    "from helpers.ollama import check_connection, build_few_shot_messages, DEFAULT_URL, DEFAULT_MODEL\n",
    "from helpers.models import parse_ollama_response\n",
    "from helpers.validate import score_breakdown\n",
    "\n",
    "print(check_connection())\n",
    "print(f\"Model: {DEFAULT_MODEL}\")\n",
    "print(f\"URL: {DEFAULT_URL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load curated angel data from DB\n",
    "SUBJECT = \"angel\"\n",
    "curated = get_curated(SUBJECT, limit=50)\n",
    "print(f\"Loaded {len(curated)} curated {SUBJECT} compositions\")\n",
    "\n",
    "# Show first 10 as a grid\n",
    "fig = draw_grid(curated[:10], cols=5, title=f\"Top 10 Curated '{SUBJECT}' Compositions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Prompt configuration — EDIT THESE to experiment\n",
    "\n",
    "# Which system prompt to use\n",
    "system_prompt = FOCUSED_SYSTEM_PROMPT\n",
    "\n",
    "# How many compositions to request per call\n",
    "PER_CALL = 10\n",
    "\n",
    "# How many curated examples to use as few-shot context\n",
    "FEW_SHOT_COUNT = 10\n",
    "\n",
    "# Ollama generation parameters\n",
    "TEMPERATURE = 0.1\n",
    "TOP_P = 0.9\n",
    "REPEAT_PENALTY = 1.1\n",
    "NUM_PREDICT = 16384\n",
    "\n",
    "# Model override (or use default)\n",
    "MODEL = DEFAULT_MODEL\n",
    "\n",
    "# Build few-shot pairs from curated data\n",
    "few_shot_comps = curated[:FEW_SHOT_COUNT]\n",
    "few_shot_pairs = []\n",
    "chunk_size = 2\n",
    "for i in range(0, len(few_shot_comps), chunk_size):\n",
    "    chunk = few_shot_comps[i:i + chunk_size]\n",
    "    user_prompt = f\"Draw {len(chunk)} distinct variation{'s' if len(chunk) > 1 else ''} of: {SUBJECT}\"\n",
    "    assistant_response = compositions_to_few_shot(SUBJECT, chunk)\n",
    "    few_shot_pairs.append((user_prompt, assistant_response))\n",
    "    print(f\"User prompt: {user_prompt}\")\n",
    "\n",
    "print(f\"Built {len(few_shot_pairs)} few-shot pairs from {len(few_shot_comps)} curated examples\")\n",
    "print(f\"Model: {MODEL}, Temperature: {TEMPERATURE}, Per call: {PER_CALL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Generate — single Ollama API call\n",
    "import time\n",
    "\n",
    "messages = build_few_shot_messages(SUBJECT, PER_CALL, few_shot_pairs, system_prompt)\n",
    "print(f\"Sending {len(messages)} messages ({sum(len(m['content']) for m in messages):,} chars total)\")\n",
    "\n",
    "t0 = time.time()\n",
    "raw_response = call_ollama(\n",
    "    messages, model=MODEL, schema=COMPOSITION_SCHEMA,\n",
    "    temperature=TEMPERATURE, top_p=TOP_P,\n",
    "    repeat_penalty=REPEAT_PENALTY, num_predict=NUM_PREDICT,\n",
    ")\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "# Parse response into AiComposition objects\n",
    "import json\n",
    "ai_comps = [AiComposition.from_dict(c) for c in raw_response.get(\"compositions\", [])]\n",
    "generated = [ai_to_composition(ac, generation_method=f\"notebook-{MODEL}\") for ac in ai_comps]\n",
    "\n",
    "print(f\"Generated {len(generated)} compositions in {elapsed:.1f}s\")\n",
    "for i, comp in enumerate(generated):\n",
    "    is_valid, score = validate(comp)\n",
    "    print(f\"  [{i}] valid={is_valid}, score={score:.4f}, strokes={count_strokes(comp)}, points={count_points(comp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Visualize generated compositions\n",
    "if generated:\n",
    "    fig = draw_grid(generated, cols=min(len(generated), 5), title=f\"Generated '{SUBJECT}' Compositions\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No compositions generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Side-by-side comparison — curated vs generated\n",
    "if generated:\n",
    "    fig = draw_comparison(\n",
    "        curated[:5], generated[:5],\n",
    "        cols=5, title=f\"'{SUBJECT}': Curated (top) vs Generated (bottom)\"\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Detailed score breakdown for each generated composition\n",
    "for i, comp in enumerate(generated):\n",
    "    breakdown = score_breakdown(comp)\n",
    "    print(f\"\\n=== Composition {i} ===\")\n",
    "    for key, val in breakdown.items():\n",
    "        print(f\"  {key}: {val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Parameter sweep — loop over temperatures\n",
    "import time\n",
    "\n",
    "temperatures = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "sweep_results = {}\n",
    "\n",
    "for temp in temperatures:\n",
    "    msgs = build_few_shot_messages(SUBJECT, PER_CALL, few_shot_pairs, system_prompt)\n",
    "    t0 = time.time()\n",
    "    try:\n",
    "        resp = call_ollama(\n",
    "            msgs, model=MODEL, schema=COMPOSITION_SCHEMA,\n",
    "            temperature=temp, top_p=TOP_P,\n",
    "            repeat_penalty=REPEAT_PENALTY, num_predict=NUM_PREDICT,\n",
    "        )\n",
    "        elapsed = time.time() - t0\n",
    "        ais = [AiComposition.from_dict(c) for c in resp.get(\"compositions\", [])]\n",
    "        comps = [ai_to_composition(ac) for ac in ais]\n",
    "        scores = [validate(c)[1] for c in comps if validate(c)[0]]\n",
    "        sweep_results[temp] = {\n",
    "            \"compositions\": comps,\n",
    "            \"scores\": scores,\n",
    "            \"avg_score\": sum(scores) / len(scores) if scores else 0,\n",
    "            \"valid_count\": len(scores),\n",
    "            \"elapsed\": elapsed,\n",
    "        }\n",
    "        print(f\"  temp={temp}: {len(scores)} valid, avg_score={sweep_results[temp]['avg_score']:.4f}, {elapsed:.1f}s\")\n",
    "    except Exception as e:\n",
    "        print(f\"  temp={temp}: ERROR — {e}\")\n",
    "        sweep_results[temp] = {\"compositions\": [], \"scores\": [], \"avg_score\": 0, \"valid_count\": 0, \"elapsed\": 0}\n",
    "\n",
    "# Plot temperature vs quality\n",
    "temps_ok = [t for t in temperatures if sweep_results[t][\"scores\"]]\n",
    "if temps_ok:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "    ax.bar([str(t) for t in temps_ok], [sweep_results[t][\"avg_score\"] for t in temps_ok], color=\"#2196F3\")\n",
    "    ax.set_xlabel(\"Temperature\")\n",
    "    ax.set_ylabel(\"Avg Quality Score\")\n",
    "    ax.set_title(f\"Temperature Sweep — '{SUBJECT}'\")\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Visualize sweep results — one row per temperature\n",
    "for temp in temperatures:\n",
    "    result = sweep_results.get(temp)\n",
    "    if result and result[\"compositions\"]:\n",
    "        fig = draw_grid(\n",
    "            result[\"compositions\"][:5], cols=5,\n",
    "            title=f\"temp={temp}  avg_q={result['avg_score']:.3f}\",\n",
    "            figsize_per_cell=2.5,\n",
    "        )\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Save good results to database\n",
    "# Only run this cell when you're happy with the generated output!\n",
    "\n",
    "# Filter to valid compositions only\n",
    "to_save = [c for c in generated if validate(c)[0]]\n",
    "print(f\"{len(to_save)} valid compositions ready to save\")\n",
    "\n",
    "# Uncomment the next line to actually save:\n",
    "# saved = save_compositions(SUBJECT, to_save, generation_method=f\"notebook-{MODEL}\")\n",
    "# print(f\"Saved {saved} compositions to database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Explore other available subjects\n",
    "try:\n",
    "    words = get_curated_words()\n",
    "    print(f\"{len(words)} words with curated data:\")\n",
    "    for w in words:\n",
    "        curated_count = len(get_curated(w, limit=1000))\n",
    "        print(f\"  {w}: {curated_count} curated compositions\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not connect to DB: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips for Prompt Tuning\n",
    "\n",
    "1. **Start with Cell 3** — change parameters and re-run cells 4-6\n",
    "2. **Temperature** — lower (0.1-0.3) = more consistent, higher (0.5-0.9) = more varied\n",
    "3. **Few-shot count** — more examples = better quality but slower generation\n",
    "4. **System prompt** — edit directly in Cell 3 or modify `helpers/ollama.py`\n",
    "5. **Use Cell 8** to find optimal temperature before committing to saves\n",
    "6. **Cell 10** saves to DB — only use when quality is consistently good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

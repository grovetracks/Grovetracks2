{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image-to-Composition Tracing\n",
    "\n",
    "Trace real-world photographs into stylized stroke compositions using computer vision.\n",
    "\n",
    "**Pipeline:** Image → Edge Detection (OpenCV Canny) → SVG Tracing (vtracer) → Stroke Extraction → Composition\n",
    "\n",
    "**Key advantages over LLM-only generation:**\n",
    "- Spatially precise — deterministic edge detection, no hallucinated coordinates\n",
    "- Free — runs entirely locally, no API costs\n",
    "- Fast — full pipeline under 1 second per image\n",
    "- Parameter tunable — adjust Canny thresholds and simplification in real-time\n",
    "\n",
    "**Optional:** Use vision LLM (Ollama or Claude) to auto-detect subject and generate tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Setup — imports and dependency checks\n",
    "%matplotlib inline\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helpers import (\n",
    "    Composition, validate, bounding_box, count_strokes, count_points,\n",
    "    draw, draw_grid, draw_comparison,\n",
    "    get_curated, save_compositions,\n",
    "    load_image, download_image, search_images, show_image, show_image_grid, show_side_by_side,\n",
    "    detect_edges, trace_to_svg, svg_to_strokes, trace_image, trace_with_params,\n",
    ")\n",
    "from helpers.validate import score_breakdown\n",
    "from helpers.vision import label_with_ollama, label_with_claude, check_vision_model\n",
    "\n",
    "# Verify core dependencies\n",
    "import cv2\n",
    "import vtracer\n",
    "import svgpathtools\n",
    "from PIL import Image\n",
    "print(f\"OpenCV: {cv2.__version__}\")\n",
    "print(f\"vtracer: OK\")\n",
    "print(f\"svgpathtools: OK\")\n",
    "print(f\"Pillow: {Image.__version__}\")\n",
    "\n",
    "# Check optional vision model\n",
    "print(f\"\\n{check_vision_model()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load an image\n",
    "# Option A: From URL\n",
    "img = load_image(\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/1200px-Cat03.jpg\")\n",
    "\n",
    "# Option B: From local file\n",
    "# img = load_image(\"images/my_photo.jpg\")\n",
    "\n",
    "# Option C: Search and browse\n",
    "# results = search_images(\"angel statue\", count=8)\n",
    "# for i, r in enumerate(results):\n",
    "#     print(f\"  [{i}] {r['description'][:60]} — {r['photographer']}\")\n",
    "# img = load_image(results[0][\"url\"])  # pick one\n",
    "\n",
    "SUBJECT = \"cat\"  # label for saving later\n",
    "\n",
    "show_image(img, title=f\"Source image: {SUBJECT} ({img.size[0]}×{img.size[1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Edge detection — tune Canny thresholds\n",
    "\n",
    "# ---- EDIT THESE to experiment ----\n",
    "CANNY_LOW = 50\n",
    "CANNY_HIGH = 150\n",
    "BLUR_KERNEL = 5\n",
    "# ----------------------------------\n",
    "\n",
    "edges = detect_edges(img, method=\"canny\", low=CANNY_LOW, high=CANNY_HIGH, blur_kernel=BLUR_KERNEL)\n",
    "\n",
    "show_side_by_side(img, edges, \"Original\", f\"Canny Edges (low={CANNY_LOW}, high={CANNY_HIGH})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: SVG tracing — convert edge map to vector paths\n",
    "\n",
    "# ---- vtracer parameters ----\n",
    "FILTER_SPECKLE = 4        # Remove small noise (higher = fewer small strokes)\n",
    "CORNER_THRESHOLD = 60     # Angle threshold for corners (degrees)\n",
    "LENGTH_THRESHOLD = 4.0    # Minimum path length\n",
    "SPLICE_THRESHOLD = 45     # Angle threshold for splicing paths\n",
    "PATH_PRECISION = 3        # Decimal precision for SVG coordinates\n",
    "# ----------------------------\n",
    "\n",
    "t0 = time.time()\n",
    "svg = trace_to_svg(\n",
    "    edges,\n",
    "    filter_speckle=FILTER_SPECKLE,\n",
    "    corner_threshold=CORNER_THRESHOLD,\n",
    "    length_threshold=LENGTH_THRESHOLD,\n",
    "    splice_threshold=SPLICE_THRESHOLD,\n",
    "    path_precision=PATH_PRECISION,\n",
    ")\n",
    "svg_time = time.time() - t0\n",
    "\n",
    "# Count paths in SVG\n",
    "import re\n",
    "path_count = len(re.findall(r'd=\"', svg))\n",
    "print(f\"SVG tracing: {path_count} paths in {svg_time:.3f}s\")\n",
    "print(f\"SVG size: {len(svg):,} chars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Stroke extraction — parse SVG → composition\n",
    "\n",
    "# ---- Simplification ----\n",
    "SIMPLIFY_TOLERANCE = 0.005  # Douglas-Peucker tolerance (higher = fewer points, sketchier)\n",
    "# ------------------------\n",
    "\n",
    "t0 = time.time()\n",
    "strokes = svg_to_strokes(svg, simplify_tolerance=SIMPLIFY_TOLERANCE)\n",
    "stroke_time = time.time() - t0\n",
    "\n",
    "comp = Composition(\n",
    "    width=255, height=255,\n",
    "    doodle_fragments=[__import__('helpers.models', fromlist=['DoodleFragment']).DoodleFragment(strokes=strokes)],\n",
    "    tags=[\"traced\", \"traced-canny\", SUBJECT],\n",
    ")\n",
    "\n",
    "is_valid, score = validate(comp)\n",
    "print(f\"Extracted {len(strokes)} strokes, {count_points(comp)} total points in {stroke_time:.3f}s\")\n",
    "print(f\"Valid: {is_valid}, Quality: {score:.4f}\")\n",
    "\n",
    "fig = draw_grid([comp], cols=1, title=f\"Traced '{SUBJECT}' (q={score:.3f}, s={len(strokes)}, p={count_points(comp)})\", figsize_per_cell=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Full pipeline — one-liner convenience\n",
    "\n",
    "t0 = time.time()\n",
    "traced = trace_image(\n",
    "    img,\n",
    "    method=\"canny\", low=CANNY_LOW, high=CANNY_HIGH,\n",
    "    simplify_tolerance=SIMPLIFY_TOLERANCE,\n",
    "    filter_speckle=FILTER_SPECKLE,\n",
    "    subject=SUBJECT,\n",
    ")\n",
    "total_time = time.time() - t0\n",
    "\n",
    "is_valid, score = validate(traced)\n",
    "print(f\"Full pipeline: {total_time:.3f}s\")\n",
    "print(f\"Strokes: {count_strokes(traced)}, Points: {count_points(traced)}, Quality: {score:.4f}\")\n",
    "\n",
    "# Show original image alongside traced composition\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "import numpy as np\n",
    "ax1.imshow(np.array(img))\n",
    "ax1.set_title(\"Original\")\n",
    "ax1.set_xticks([]); ax1.set_yticks([])\n",
    "draw(traced, ax=ax2, title=f\"Traced (q={score:.3f})\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Parameter tuning — sweep Canny thresholds\n",
    "\n",
    "param_sets = [\n",
    "    {\"low\": 30, \"high\": 100, \"simplify_tolerance\": 0.003},\n",
    "    {\"low\": 50, \"high\": 150, \"simplify_tolerance\": 0.005},\n",
    "    {\"low\": 80, \"high\": 200, \"simplify_tolerance\": 0.005},\n",
    "    {\"low\": 100, \"high\": 250, \"simplify_tolerance\": 0.008},\n",
    "    {\"low\": 50, \"high\": 150, \"simplify_tolerance\": 0.015},\n",
    "]\n",
    "\n",
    "traced_variants = trace_with_params(img, param_sets, subject=SUBJECT)\n",
    "\n",
    "titles = []\n",
    "for i, (comp, params) in enumerate(zip(traced_variants, param_sets)):\n",
    "    is_valid, score = validate(comp)\n",
    "    s = count_strokes(comp)\n",
    "    p = count_points(comp)\n",
    "    label = f\"lo={params.get('low', 50)} hi={params.get('high', 150)}\\nsimp={params.get('simplify_tolerance', 0.005)}\\nq={score:.3f} s={s} p={p}\"\n",
    "    titles.append(label)\n",
    "    print(f\"  [{i}] low={params.get('low')}, high={params.get('high')}, simp={params.get('simplify_tolerance')}: q={score:.4f}, s={s}, p={p}\")\n",
    "\n",
    "# Draw all variants in a grid\n",
    "n = len(traced_variants)\n",
    "fig, axes = plt.subplots(1, n, figsize=(4 * n, 4))\n",
    "if n == 1:\n",
    "    axes = [axes]\n",
    "for i, (comp, title) in enumerate(zip(traced_variants, titles)):\n",
    "    draw(comp, ax=axes[i], title=title)\n",
    "fig.suptitle(f\"Parameter Sweep: '{SUBJECT}'\", fontsize=14, fontweight=\"bold\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Edge method comparison\n",
    "\n",
    "methods = [\n",
    "    {\"method\": \"canny\", \"low\": 50, \"high\": 150},\n",
    "    {\"method\": \"canny\", \"low\": 30, \"high\": 100},\n",
    "    {\"method\": \"adaptive\"},\n",
    "]\n",
    "\n",
    "method_results = trace_with_params(img, methods, subject=SUBJECT)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(methods) + 1, figsize=(4 * (len(methods) + 1), 4))\n",
    "import numpy as np\n",
    "axes[0].imshow(np.array(img))\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[0].set_xticks([]); axes[0].set_yticks([])\n",
    "\n",
    "for i, (comp, params) in enumerate(zip(method_results, methods)):\n",
    "    is_valid, score = validate(comp)\n",
    "    method = params.get('method', 'canny')\n",
    "    draw(comp, ax=axes[i + 1], title=f\"{method}\\nq={score:.3f} s={count_strokes(comp)}\")\n",
    "\n",
    "fig.suptitle(f\"Edge Method Comparison: '{SUBJECT}'\", fontsize=14, fontweight=\"bold\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Vision labeling (optional) — auto-detect subject and tags\n",
    "# Requires a vision model in Ollama (e.g., qwen2.5-vl:7b) or Claude API key\n",
    "\n",
    "# Option A: Ollama vision model (local, free)\n",
    "try:\n",
    "    print(\"Labeling with Ollama vision model...\")\n",
    "    labels = label_with_ollama(img)\n",
    "    print(f\"  Subject: {labels['subject']}\")\n",
    "    print(f\"  Tags: {labels['tags']}\")\n",
    "    print(f\"  Description: {labels['description']}\")\n",
    "    SUBJECT = labels[\"subject\"]  # Update subject for saving\n",
    "except Exception as e:\n",
    "    print(f\"  Ollama vision not available: {e}\")\n",
    "    print(\"  To use: ollama pull qwen2.5-vl:7b\")\n",
    "\n",
    "# Option B: Claude (cloud, costs money)\n",
    "# from helpers.claude import UsageTracker\n",
    "# tracker = UsageTracker()\n",
    "# labels = label_with_claude(img, tracker=tracker)\n",
    "# print(f\"Subject: {labels['subject']}, Tags: {labels['tags']}\")\n",
    "# print(f\"Cost: {tracker.summary()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Compare traced vs curated Quick Draw data\n",
    "try:\n",
    "    curated = get_curated(SUBJECT, limit=10)\n",
    "    if curated:\n",
    "        print(f\"Found {len(curated)} curated '{SUBJECT}' compositions\")\n",
    "        fig = draw_comparison(\n",
    "            curated[:5], [traced],\n",
    "            cols=5, title=f\"'{SUBJECT}': Curated Quick Draw (top) vs Traced Photo (bottom)\"\n",
    "        )\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No curated data for '{SUBJECT}'\")\n",
    "        fig = draw_grid([traced], cols=1, title=f\"Traced '{SUBJECT}'\", figsize_per_cell=5)\n",
    "        plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"DB not available: {e}\")\n",
    "    fig = draw_grid([traced], cols=1, title=f\"Traced '{SUBJECT}'\", figsize_per_cell=5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Batch tracing — multiple images\n",
    "\n",
    "urls = [\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Cat03.jpg/1200px-Cat03.jpg\",\n",
    "    # Add more URLs here:\n",
    "    # \"https://example.com/another-image.jpg\",\n",
    "]\n",
    "\n",
    "batch_results = []\n",
    "for i, url in enumerate(urls):\n",
    "    try:\n",
    "        batch_img = load_image(url)\n",
    "        batch_comp = trace_image(batch_img, low=CANNY_LOW, high=CANNY_HIGH, simplify_tolerance=SIMPLIFY_TOLERANCE, subject=SUBJECT)\n",
    "        is_valid, score = validate(batch_comp)\n",
    "        batch_results.append(batch_comp)\n",
    "        print(f\"  [{i}] {url[:60]}... → q={score:.4f}, s={count_strokes(batch_comp)}, p={count_points(batch_comp)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  [{i}] {url[:60]}... → ERROR: {e}\")\n",
    "\n",
    "if batch_results:\n",
    "    fig = draw_grid(batch_results, cols=min(len(batch_results), 5), title=f\"Batch Traced: '{SUBJECT}'\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Save to database\n",
    "# Only run when you're happy with the results!\n",
    "\n",
    "to_save = [traced] + [c for c in batch_results if validate(c)[0]] if batch_results else [traced]\n",
    "to_save = [c for c in to_save if validate(c)[0]]\n",
    "print(f\"{len(to_save)} valid compositions ready to save\")\n",
    "\n",
    "for i, comp in enumerate(to_save):\n",
    "    is_valid, score = validate(comp)\n",
    "    print(f\"  [{i}] q={score:.4f}, s={count_strokes(comp)}, p={count_points(comp)}\")\n",
    "\n",
    "# Uncomment to save:\n",
    "# saved = save_compositions(SUBJECT, to_save, generation_method=\"traced-canny\")\n",
    "# print(f\"Saved {saved} compositions to database\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips for Tuning Trace Parameters\n",
    "\n",
    "### Canny Edge Detection\n",
    "- **low/high thresholds**: Lower values = more edges (more detail, more noise). Higher = cleaner but may lose features.\n",
    "- **Typical ranges**: low=30-100, high=100-250. Try `low=50, high=150` as a starting point.\n",
    "- **blur_kernel**: Larger values smooth the image more before edge detection. Use 3-7.\n",
    "\n",
    "### vtracer Parameters\n",
    "- **filter_speckle**: Higher values remove small noise strokes (default 4, try 2-10).\n",
    "- **corner_threshold**: Controls how sharp corners must be to be kept (degrees, default 60).\n",
    "- **length_threshold**: Minimum path length to keep (default 4.0).\n",
    "\n",
    "### Simplification\n",
    "- **simplify_tolerance**: Douglas-Peucker tolerance. Higher = fewer points, sketchier look.\n",
    "  - 0.002 — very detailed, many points\n",
    "  - 0.005 — balanced (default)\n",
    "  - 0.010 — simplified, fewer points\n",
    "  - 0.020 — very sketchy, minimal points\n",
    "\n",
    "### Image Source Tips\n",
    "- **High contrast** photos trace better than low-contrast ones.\n",
    "- **Simple backgrounds** (white, solid color) produce cleaner edge maps.\n",
    "- **Subject should fill the frame** — the composition is normalized to fill the canvas.\n",
    "- Use `search_images(\"cat white background\")` for clean source images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
